---
title: "Comparing Designs"
description: "Effectively compare design alternatives to make informed decisions and build stakeholder consensus."
icon: "balance-scale"
---

# Comparing Designs

Making design decisions is easier when you can clearly see alternatives side-by-side. Figr provides powerful comparison tools that help teams evaluate options and build consensus.

<Callout type="success">
**Data-driven design decisions:** Move beyond subjective preferences to objective comparison based on user needs, business goals, and technical constraints.
</Callout>

## Comparison Methods

<Tabs>
  <Tab title="Side-by-Side Views">
    **Visual comparison layouts:**
    
    <Frame>
      <img src="/images/side-by-side-comparison.png" alt="Two design alternatives displayed side-by-side with comparison annotations" />
    </Frame>
    
    **Layout options:**
    ```yaml
    Split view: 50/50 vertical division
    Multi-column: 3+ designs in columns
    Carousel: Swipe between alternatives
    Overlay: Designs stacked with transparency
    Grid: Matrix view for many options
    ```
  </Tab>
  
  <Tab title="Interactive Comparison">
    **Dynamic evaluation tools:**
    
    <CardGroup cols={2}>
      <Card title="Hover Switching" icon="mouse-pointer">
        Hover over areas to switch between design alternatives instantly
      </Card>
      
      <Card title="Slider Comparison" icon="sliders">
        Drag slider to reveal different designs progressively
      </Card>
    </CardGroup>
    
    **Advanced interactions:**
    ```
    üéØ Focus mode: Highlight specific elements
    üîç Zoom sync: Synchronized zooming across designs
    üì± Device preview: Compare across screen sizes
    ‚ö° Animation: Smooth transitions between options
    ```
  </Tab>
  
  <Tab title="Annotated Analysis">
    **Structured comparison framework:**
    
    <AccordionGroup>
      <Accordion title="Feature Comparison">
        ```yaml
        Compare specific aspects:
        - User flow efficiency
        - Visual hierarchy clarity
        - Information density
        - Accessibility compliance
        - Mobile responsiveness
        - Brand consistency
        ```
      </Accordion>
      
      <Accordion title="Evaluation Criteria">
        ```yaml
        Scoring framework:
        - User experience (1-10)
        - Technical feasibility (1-10)
        - Business alignment (1-10)
        - Design quality (1-10)
        - Implementation time (1-10)
        ```
      </Accordion>
    </AccordionGroup>
  </Tab>
</Tabs>

## Comparison Frameworks

<Steps>
  <Step title="User-Centered Comparison">
    **Evaluate based on user needs:**
    
    <Tabs>
      <Tab title="Task Completion">
        ```yaml
        Measure effectiveness:
        - Steps to complete primary task
        - Cognitive load assessment
        - Error prevention capabilities
        - Recovery from mistakes
        - Learning curve steepness
        ```
      </Tab>
      
      <Tab title="User Preferences">
        ```yaml
        Preference indicators:
        - First impression ratings
        - Perceived trustworthiness
        - Aesthetic appeal scores
        - Functional clarity ratings
        - Overall satisfaction
        ```
      </Tab>
    </Tabs>
  </Step>
  
  <Step title="Business Impact Analysis">
    **Connect design to business outcomes:**
    
    ```yaml
    Business metrics:
    Conversion potential: Which design drives more actions
    Brand alignment: Consistency with brand values
    Competitive position: Differentiation from competitors
    Market appeal: Target audience resonance
    Revenue impact: Projected business value
    ```
  </Step>
  
  <Step title="Technical Feasibility">
    **Implementation reality check:**
    
    <CardGroup cols={2}>
      <Card title="Development Effort" icon="code">
        - Implementation complexity
        - Required development time
        - Technical risk assessment
        - Resource requirements
      </Card>
      
      <Card title="Performance Impact" icon="gauge">
        - Page load implications
        - Rendering performance
        - Accessibility compliance
        - Cross-browser compatibility
      </Card>
    </CardGroup>
  </Step>
</Steps>

## Team Decision Making

<Tabs>
  <Tab title="Stakeholder Reviews">
    **Structured decision processes:**
    
    <Frame>
      <img src="/images/stakeholder-comparison.png" alt="Interface showing stakeholder voting and feedback on design alternatives" />
    </Frame>
    
    **Review workflow:**
    ```yaml
    1. Present alternatives clearly
    2. Explain evaluation criteria
    3. Gather structured feedback
    4. Discuss pros and cons
    5. Document decision rationale
    ```
  </Tab>
  
  <Tab title="Team Voting">
    **Democratic design decisions:**
    
    <AccordionGroup>
      <Accordion title="Weighted Voting">
        ```yaml
        Vote weighting by role:
        - Users/Customers: 40%
        - Product Manager: 25%
        - Lead Designer: 20%
        - Tech Lead: 15%
        
        Custom weighting available
        ```
      </Accordion>
      
      <Accordion title="Criteria-Based Scoring">
        ```yaml
        Score each design on:
        - User experience quality
        - Technical implementation
        - Business goal alignment
        - Timeline feasibility
        - Risk assessment
        ```
      </Accordion>
    </AccordionGroup>
  </Tab>
  
  <Tab title="Consensus Building">
    **Collaborative decision making:**
    
    ```yaml
    Consensus tools:
    - Anonymous initial feedback
    - Open discussion threads
    - Compromise alternative creation
    - Final agreement documentation
    - Decision appeal process
    ```
  </Tab>
</Tabs>

## A/B Testing Integration

<Steps>
  <Step title="Test Design Setup">
    **Prepare designs for user testing:**
    
    ```yaml
    Test preparation:
    - Ensure comparable functionality
    - Match content and data
    - Standardize testing conditions
    - Define success metrics
    - Plan statistical significance
    ```
  </Step>
  
  <Step title="Results Analysis">
    **Interpret testing data:**
    
    <CardGroup cols={2}>
      <Card title="Quantitative Results" icon="chart-bar">
        - Conversion rates
        - Task completion times
        - Error rates
        - Engagement metrics
      </Card>
      
      <Card title="Qualitative Insights" icon="comments">
        - User feedback themes
        - Behavioral observations
        - Preference explanations
        - Usability issues
      </Card>
    </CardGroup>
  </Step>
  
  <Step title="Design Iteration">
    **Apply learnings to improve designs:**
    
    ```yaml
    Post-test improvements:
    - Combine winning elements
    - Address identified issues
    - Create hybrid solutions
    - Plan follow-up tests
    ```
  </Step>
</Steps>

## Comparison Documentation

<Callout type="info">
**Decision history:** Document comparison rationale to inform future decisions and build institutional knowledge.
</Callout>

<Tabs>
  <Tab title="Decision Records">
    **Capture decision context:**
    
    ```yaml
    Document for each comparison:
    - Alternatives considered
    - Evaluation criteria used
    - Stakeholders involved
    - Decision rationale
    - Expected outcomes
    - Success metrics defined
    ```
  </Tab>
  
  <Tab title="Learning Capture">
    **Build design knowledge:**
    
    ```yaml
    Pattern recognition:
    - Which design approaches work best
    - Common decision factors
    - Stakeholder preference patterns
    - User testing insights
    - Implementation learnings
    ```
  </Tab>
</Tabs>

## Advanced Comparison Features

<CardGroup cols={2}>
  <Card title="AI-Assisted Analysis" icon="brain">
    **Intelligent comparison insights:**
    
    - Pattern recognition across designs
    - Best practice compliance checking
    - User research alignment analysis
    - Accessibility gap identification
  </Card>
  
  <Card title="Historical Comparison" icon="history">
    **Learn from past decisions:**
    
    - Compare with previous successful designs
    - Track decision pattern evolution
    - Identify recurring design challenges
    - Reference proven solutions
  </Card>
</CardGroup>

## Best Practices

<Steps>
  <Step title="Fair Comparison Setup">
    **Ensure objective evaluation:**
    
    ```
    ‚úÖ Use equivalent content and data
    ‚úÖ Test under similar conditions
    ‚úÖ Consider all user scenarios
    ‚úÖ Include edge cases and errors
    ‚úÖ Account for different skill levels
    ```
  </Step>
  
  <Step title="Comprehensive Evaluation">
    **Consider multiple perspectives:**
    
    ```
    ‚úÖ User experience and usability
    ‚úÖ Business goal achievement
    ‚úÖ Technical implementation reality
    ‚úÖ Brand and design consistency
    ‚úÖ Long-term maintainability
    ```
  </Step>
  
  <Step title="Decision Communication">
    **Share decisions effectively:**
    
    ```
    ‚úÖ Clear rationale explanation
    ‚úÖ Acknowledge trade-offs made
    ‚úÖ Document next steps
    ‚úÖ Plan success measurement
    ‚úÖ Create implementation timeline
    ```
  </Step>
</Steps>

---

<Card title="Explore Canvas Overview" icon="map">
  Learn how to use zooming and overview features to navigate large design projects effectively.
  
  [Zooming Overview ‚Üí](/designing/canvas/zooming-overview)
</Card>
